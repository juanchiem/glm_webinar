---
title: "GLM regresion"
output: html_document
date: '2022-06-09'
---

# Setup 

Cargamos paquetes de utilidad para esta sesión y configuramos la estetica global de los graficos. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, 
               sjPlot, 
               lme4, 
               emmeans, 
               multcomp)
theme_set(theme_bw())
```

# Demo

## Dist. Normal

Todos conocemos 
```{r}
set.seed(1)

x=rnorm(n=100,    # sample size
        mean=10,  # mean of sample
        sd=3      # standard deviation of sample
        )
hist(x)
head(x)

mu = 3 + 2*x      # linear prediction
plot(x,mu)

## generate y from prediction with a normal error distribution
y=rnorm(n=100,    # sample size
        mean=mu,  # mean of sample
        sd=3      # standard deviation of sample
        )
plot(x,y)
```

## Rev. Modelo lineal

```{r}
mod1 <- lm(y~x)
plot_model(mod1, type='pred', show.data=T, ci.lvl = NA)
summary(mod1)
```

```{r}
mod1.1 <- glm(y~x, family = "gaussian")
plot_model(mod1.1, type='pred', show.data=T, ci.lvl = NA)
summary(mod1.1)
```

## Dist. Binomial

Diferencias entre tamaño de muestra y numero de trials

```{r}
bin_1 <- rbinom(
    n=10,     # number of observations
    size=100, # number of trials
    p=0.5     # probability of success
    )
bin_1
hist(bin_1); rug(bin_1, col="red")

bin_2 <- rbinom(
    n=10,     # number of observations
    size=1,   # number of trials
    p=0.5     # probability of success
    )
bin_2
hist(bin_2); rug(bin_2, col="red")

```

# Datos simulados

Imaginemos que tomamos todos los alumnos de una clase n=24, y luego de un examen les pedimos que nos digan cuantas horas dedicaron a estudiar la prueba. Asi podemos agruparlos de a 4 entre 1 a 6 horas en la ultima semana. 
El examen se aprueba con al menos nota 7, por lo que obtendremos una linea de corte para determinar los aprobados (nota>=7) y desaprobados (nota<7).

```{r}
horas <- c(1, 1, 1, 1, 
           2, 2, 2, 2,
           3, 3, 3, 3, 
           4, 4, 4, 4, 
           5, 5, 5, 5, 
           6, 6, 6, 6 
           )

# variable discreta  
nota  <- c(3, 5, 4, 7, 
           6, 5, 7, 3, 
           8, 6, 8, 5, 
           9, 5, 10, 6, 
           9, 7, 6, 9, 
           9, 10, 10, 9 
           )
# generamos una variable binomial

df <- data.frame(horas, nota) %>% 
  mutate(aprobo =ifelse(nota>=7,1,0))
```

Visualicemos las notas obtenidas en funcion de las horas dedicadas a estudiar la materia

```{r}
df %>% 
  ggplot() + 
  aes(x=horas, y=nota) + 
  stat_smooth()+
  geom_point()
```

En nuestro caso nos interesaria evaluar y modelar la probabilidad de aprobar (nota>=7) segun la cantidad de horas dedicadas a estudiar el examen.

Esto lo podemos realizar de tres maneras con glm! 

Directamente con la variable binomial: aprobó=1 o desaprobó=0

Con `r df` que contiene una observacion por fila

```{r}
p1 <- df %>% 
  ggplot() + 
  aes(x=horas, y=aprobo) + 
  geom_count(alpha=.5) +
  geom_smooth(method = "glm", se = F, fullrange=FALSE, size=0.6,
              method.args = list(family = "binomial")) +
  scale_x_continuous(labels=as.character(horas),breaks=horas)
```

```{r}
m1 <- glm(aprobo ~ horas,
          family = binomial(link = 'logit'), 
          data=df)
```

Con `r df_sum` que resume la cantidad de exitos totales por cada n de cada nota.

```{r}
df_sum <- df %>% 
    group_by(horas) %>% 
    summarise(
        n = sum(!is.na(aprobo)), 
        aprobados = sum(aprobo))
df_sum
```

```{r}
p2 <- df_sum %>% 
  ggplot() + 
  aes(x=horas, y=aprobados/n) + 
  stat_summary(fun=mean, col="red")+
  geom_smooth(method = "glm", se =F, fullrange=FALSE, size=0.6,
              method.args = list(family = "binomial")) +
  scale_x_continuous(labels=as.character(horas),breaks=horas)+
    ylim(0,1)
    

# df_sum %>% 
#   ggplot() + 
#   aes(x=horas, y=aprobo) + 
#   stat_summary(fun=mean, col="red")+
#   geom_smooth(method = "glm", se = T, fullrange=FALSE, size=0.6,
#               method.args = list(family = "binomial")) +
#   scale_x_continuous(labels=as.character(horas),breaks=horas)

```


```{r}
m2 <- glm(cbind(aprobados, n-aprobados) ~ horas,  
          family = binomial(link = 'logit'),  
          data=df_sum)
```

O bien con las proporciones dentro de cada hora de estudio (aprobados/total)

```{r}
df_sum_prop <- df_sum %>% 
    group_by(horas) %>% 
    summarise(n=first(n), 
              prop_aprob = aprobados/n)
df_sum_prop
```

```{r}
p3 <- df_sum_prop %>% 
    ggplot() + 
    aes(x=horas, y=prop_aprob) + 
    geom_point() +
    geom_smooth(method = "glm", se = F, fullrange=FALSE, size=0.6,
                method.args = list(family = "binomial")) +
    scale_x_continuous(labels=as.character(horas),breaks=horas)+
    ylim(0,1)
```

```{r}
m3 <- glm(prop_aprob ~ horas,  
          family = binomial(link = 'logit'), 
          weights = n,
          data=df_sum_prop)
```

```{r}
library(patchwork)
p1 + p2 + p3 
```

```{r}
tab_model(m1,m2, m3)
```

```{r}
plot_model(m1, type='pred', show.data=T, terms='horas')
```



```{r}
# generate data
# set.seed(1)
# x = rnorm(100, 12, 4)             ## sample x from a normal distribution
# mu = 1 + 0.5*x                   ## linear predictor
# prob = 1 / (1 + exp(-mu))         ## transform linear predictor with inverse of "logit" link
# y = rbinom(100, 1, prob = prob)   ## sample y from probabilities with binomial error distribution
# hist(y)
# plot(x,y)
```

```{r}
binomial_dat <- rio::import("https://raw.githubusercontent.com/juanchiem/agro_data/master/binomial.csv")
binomial_dat %>% head
# llamemos a este tipo de dataset: "binomial desplegado"
with(binomial_dat, plot(x,y))
```

```{r}
mod_lm_2 <- lm(y ~ x, data=binomial_dat)
plot_model(mod_lm_2, type='pred', show.data=T, ci.lvl=NA)
```

```{r}
glm1 <- glm(y~x, 
           family = binomial(link = 'logit'), 
           data=binomial_dat)
```

```{r}
plot_model(glm1, type='pred', show.data=T, terms='x [all]')
```

```{r}
binomial()
poisson()
```

Ultima aclaracion! 
vimos como 


# Data 

```{r}
# maracuya <- "https://raw.githubusercontent.com/juanchiem/agro_data/master/maracuya_roug.txt"
# raw <- rio::import(maracuya, header=TRUE) %>% tibble
raw <- rio::import("david/maracuya_roug.txt", header = TRUE) %>% tibble

dat <- raw %>%  
  # dplyr::select(-inc) %>% 
  # rio::export(file = "david/maracuya_roug.txt")  
  mutate_at(vars(trt, bk), as.factor) %>% 
  mutate(inc_prop=dis_plants/n_plants)  # %>% 

dat %>%
    ggplot() +
    aes(x=days, y=inc_prop, col=trt, shape=bk)+
    geom_point()+
    geom_line(aes(group=interaction(bk,trt))) 
```

Filtramos el dataset completo para subsets de menos evaluaciones

```{r}
# solo una evaluación a los 60 dias 
dat1 <- dat %>% 
  filter(days %in% c(60))

# solo una evaluación a los 90 dias 
dat2 <- dat %>% 
  filter(days %in% c(90))

# Dos evaluaciones: a los 60 y 90 dias 
dat3 <- dat %>% 
  filter(days %in% c(60, 90)) %>% 
  mutate_at(vars(days), as.factor) 
```

# Modelos

Un solo momento de evaluacion 

# · 60 d

```{r}
dat1

dat1 %>% 
  ggplot() + 
  aes(x=trt, y=inc) + 
  geom_point()
```


```{r}
# mod1 <- glmer(
#   cbind(dis_plants, n_plants-dis_plants) ~ trt + (1|bk), 
#   family="binomial", 
#   data=dat1) 

mod1 <- glmer(
  inc ~ trt + (1|bk),
  weights=n_plants, # observations per trial
  family="binomial", 
  data=dat1) 

car::Anova(mod1)
summary(mod1)
tab_model(mod1)

plot_model(mod1, type='pred', show.data=T)
em1 <- emmeans(mod1, ~ trt, type="response")
res1 <- cld(em1, Letters = letters, alpha = .05, type = "response")
knitr::kable(res1)
```

el cociente entre la deviance relativa (en adelante deviance) y los grados de libertad residuales debería estar cerca de 1 si el ajuste es razonable. Un valor grande de este cociente significa que la varianza es mayor que la esperada bajo la distribución correspondiente (sobredispersión). Se suele usar un valor
de hasta 2.5 para el cociente como indicador de que no hay una sobredispersión importante.

```{r}
overdisp_fun(mod1)
```

# · 90 d

```{r}
dat2

dat2 %>% 
  ggplot() + 
  aes(x=trt, y=inc) + 
  geom_point()

# mod1 <- glmer(
#   cbind(dis_plants, n_plants-dis_plants) ~ trt + (1|bk), 
#   family="binomial", 
#   data=dat1)
```


```{r}
mod2 <- glmer(
  inc ~ trt + (1|bk),
  weights=n_plants,
  family="binomial", 
  data=dat2) 

car::Anova(mod2)
summary(mod2)
overdisp_fun(mod2)

tab_model(mod2)
plot_model(mod1, type='pred', show.data=T)

em2 <- emmeans(mod2, ~ trt, type="response")
res2 <- cld(em2, Letters = letters, alpha = .05, type = "response")
knitr::kable(res2)

```


# · 60 y 90 d 

```{r}
dat3

dat3 %>% 
  ggplot() +
  aes(x=days, y=inc, col=trt, shape=bk)+
  geom_point()
```


```{r}
mod3 <- glmer(inc ~ trt * days + (1|bk),
              weights=n_plants,
              family="binomial",
              data=dat3) 

car::Anova(mod3)

mod3.1 <- glmer(inc ~ trt + days + (1|bk),
              weights=n_plants,
              family="binomial",
              data=dat3) 
anova(mod3, mod3.1, test = "Chisq")
AIC(mod3, mod3.1)

summary(mod3.1)
overdisp_fun(mod3.1)
tab_model(mod3.1)
plot_model(mod3.1, 
           terms = c("days", "trt"), 
           type='pred', show.data=T)
em3 <- emmeans(mod3, ~ trt|days, type="response")
res3 <- cld(em3, Letters = letters, alpha = .05, type = "response")
knitr::kable(res3)
```


#· Serie full

```{r}
head(dat)
dat %>% 
  ggplot() +
  aes(x=days, y=inc, col=trt, shape=bk)+
  geom_point()

mod_serie <- glmer(inc ~ trt * days + (1|bk) + (1|bk:trt),
              weights=n_plants,
              family="binomial",
              data=dat) 
car::Anova(mod_serie)
overdisp_fun(mod_serie)
tab_model(mod_serie)
plot_model(mod_serie, 
           terms = c("days", "trt"), 
           type='pred', show.data=T)

```

```{r}
mod_serie0 <- glmer(inc ~ days + (1|bk) + (1|bk:trt),
              weights=n_plants,
              family="binomial",
              data=dat) 

mod_serie1 <- glmer(inc ~ days + (1|bk:trt),
              weights=n_plants,
              family="binomial",
              data=dat) 
```

## Seleccion de modelo

```{r}
anova(mod_serie0, mod_serie, test = "Chisq")
AIC(mod_serie0, mod_serie, mod_serie1)
```

```{r}
parameters::model_parameters(mod_serie, effects = "all")
summary(mod_serie)
car::Anova(mod_serie)

tab_model(mod_serie)
plot_model(mod2, type = "pred", terms = c("days", "roug"))
```


Pred. lineal roug:no = -3.275 + 0.025 * days 
Pred. lineal roug:yes = (-3.275 + 0.147) + (0.025 - 0.012) * days 


## Prediccion

```{r}
df_predict = data.frame(trt=c("no", "yes"), bk=2, days=150)

predict(mod_serie, 
        newdata= df_predict, 
        type="response")

dat %>%
  mutate(
    pred_mod = predict(mod_serie),
    fitted_mod = fitted(mod_serie)
    ) 
```

```{r}
dat %>% 
  ggplot(aes(x = days, y = inf_plants/n_plants, col=roug))+
  geom_point()+    
  geom_smooth(method = "glm", se = F, fullrange=TRUE,
              method.args = list(family = "binomial"))
```

