---
title: "Untitled"
output: html_document
---
Datos simulados

Imaginemos que tomamos todos los alumnos de una clase n=24, y luego de un examen les pedimos que nos digan cuantas horas dedicaron a estudiar la prueba. 

El examen se aprueba con al menos nota 7, por lo que obtendremos una linea de corte para determinar los aprobados (nota>=7) y desaprobados (nota<7).

```{r}
horas <- c(1, 1, 1, 1, 
           2, 2, 2, 2,
           3, 3, 3, 3, 
           4, 4, 4, 4, 
           5, 5, 5, 5, 
           6, 6, 6, 6 
           )

# variable discreta  
nota  <- c(3, 5, 4, 7, 
           6, 5, 7, 3, 
           8, 6, 8, 5, 
           9, 5, 10, 6, 
           9, 7, 6, 9, 
           9, 10, 10, 9 
           )

# generamos una variable binomial
df <- data.frame(horas, nota) %>% 
  mutate(aprobo =ifelse(nota>=7,1,0))
df
xtabs(~ aprobo + horas, df)

```

Visualicemos las notas obtenidas en funcion de las horas dedicadas a estudiar la materia

```{r}
df %>% 
  ggplot() + 
  aes(x=horas, y=nota) + 
  stat_smooth()+
  geom_point()
```

...Y ahora los aprobados

```{r}
df %>% 
  ggplot() + 
  aes(x=horas, y=aprobo) + 
  geom_count(alpha=.5) +
  stat_smooth(method="lm", fullrange=TRUE)+
  coord_cartesian(xlim=c(0,7), ylim=c(0,1.2)) +
  scale_x_continuous(expand=c(0,0), limits=c(0,7)) 
```

Vemos que nuestro modelo estaria excedediendo los limites de nuestra variable respuesta (0 a 1)

En nuestro caso nos interesaria evaluar y modelar la probabilidad de aprobar (nota>=7) segun la cantidad de horas dedicadas a estudiar el examen.

Esto lo podemos realizar de tres maneras con glm! 

## Individual data 

Directamente con la variable binomial: aprobó=1 o desaprobó=0

Con `r df` que contiene una observacion por fila 

```{r}
df # cada fila es una observacion 

p1 <- df %>% 
  ggplot() + 
  aes(x=horas, y=aprobo) + 
  geom_count(alpha=.5) +
  geom_smooth(method = "glm", se = F, fullrange=FALSE, size=0.6,
              method.args = list(family = "binomial")) +
  scale_x_continuous(labels=as.character(horas),breaks=horas)+ 
  ggtitle("Data individual ")
p1
```

```{r}
m1 <- glm(aprobo ~ horas,
          family = binomial(link = 'logit'), 
          data=df)
```

## Grouped data

Con `r df_sum` que resume la cantidad de exitos totales por cada n de cada nota.

```{r}
df_sum # agrupa las observaciones para cada nivel de x en las columnas "n" y "aprobados" con la suma de exitos totales

df_sum <- df %>% 
    group_by(horas) %>% 
    summarise(
        n = sum(!is.na(aprobo)), 
        aprobados = sum(aprobo))
df_sum
```

```{r}
p2 <- df_sum %>% 
  ggplot() + 
  aes(x=horas, y=aprobados/n) + 
  stat_summary(fun=mean, col="red")+
  geom_smooth(method = "glm", se =F, fullrange=FALSE, size=0.6,
              method.args = list(family = "binomial")) +
  scale_x_continuous(labels=as.character(horas),breaks=horas)+
  ylim(0,1) + 
  ggtitle("Data agrupada")

p2
```


```{r}
m2 <- glm(
  cbind(aprobados, n-aprobados) ~ horas,  # matriz de exitos y fracasos
          family = binomial(link = 'logit'),  
          data=df_sum)
```

## Proporciones 

O bien con las proporciones dentro de cada hora de estudio (aprobados/total)

```{r}
df_sum_prop <- df_sum %>% 
    group_by(horas) %>% 
    summarise(n=first(n), 
              aprob_prop = aprobados/n)
df_sum_prop 
# similar al df_sum pero con una columna con la suma total de casos (n) y el calculo de la proporcion de exitos en cada nivel de x (aprob_prop) 
```

```{r}
p3 <- df_sum_prop %>% 
    ggplot() + 
    aes(x=horas, y=aprob_prop) + 
    geom_point() +
    geom_smooth(method = "glm", se = F, fullrange=FALSE, size=0.6,
                method.args = list(family = "binomial")) +
    scale_x_continuous(labels=as.character(horas),breaks=horas)+
    ylim(0,1) + 
    ggtitle("Proporcion")

p3
```

```{r}
m3 <- glm(aprob_prop ~ horas,  # y es una proporcion 0 a 1 
          family = binomial(link = 'logit'), 
          weights = n,         # informamos el nro de ensayos de cada fila
          data=df_sum_prop)
```

veamos que tal se ven esos datos y principalmente las lineas de tendencias

```{r}
library(patchwork)
p1 + p2 + p3 
```

Coeficientes 

```{r}
tab_model(m1,m2, m3)
# exactamente iguales!
```

Que tal se ve el modelo ajustado?

```{r}
plot_model(m1, type='pred', show.data=T, terms='horas')
```

Mas info sobre estos diferentes abordajes aqui: 

https://www.sciencedirect.com/science/article/pii/S0895435600002924?via%3Dihub

https://thestatsgeek.com/2014/02/08/r-squared-in-logistic-regression/

Interpretemos los coeficientes:

```{r}
summary(m1)
```

El "log odds" de aprobar/desaprobar el examen estaria dada por: 

log(p/1-p) = -2.327 + 0.73 x

Pero el odds ratio de cada hora de estudio adicional estaria dado por: 

```{r}
odds_ratio_h = exp(m1$coefficients[-1])
odds_ratio_h

# 2.07554 --- o sea que cada hora de estudio duplica la chance de aprobar
# como vimos en la tab_model(m1) 
tab_model(m1)
```

Aqui observamos lo mismo, solo que le agrega el IC y la significancia. 

Vemos que (1.19 - 4.35) no contiene a 1 y que el valor p < 0.05, por lo tanto concluimos que las chances / probabilidad de aprobar esta relacionado con las horas de estudio que le dedicaron los alumnos.  

Expresado en % 

```{r}
(odds_ratio_h - 1)*100
# 107.5 %  >>> o sea que por cada hora de estudio aumenta el 107% las chances de aprobar
```

# Dianosticos

https://stats.stackexchange.com/questions/185491/diagnostics-for-generalized-linear-mixed-models-specifically-residuals 

paquete DHARMa

https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html#goodness-of-fit-tests-on-the-scaled-residuals

```{r}
library(DHARMa)
testOutliers(m1)
testDispersion(m1)
simulationOutput <- simulateResiduals(fittedModel = m1)
plot(simulationOutput)

```


# Bondad de ajuste

McFadden's Pseudo R^2 

R^2 = [ LL(Null) - LL(Proposed) ] / LL(Null)

(semejante interpretacion que el R2 de regresion OLS, solo que valores entre 0.2-0.4 indican buen ajuste del modelo.

```{r}
# ll.null <- m1$null.deviance/-2
# ll.proposed <- m1$deviance/-2
# (ll.null - ll.proposed) / ll.null
```
 
```{r}
pacman::p_load(pscl)
pR2(m1)
```

# Predecir

Para aquellos que estudiaron 1 hora

```{r}
predict(m1,                           # modelo que ajustamos 
        newdata= data.frame(horas=1), # que valor/nivel de X 
        type="response")              # probabilidad
```
